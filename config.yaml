# Model Architecture
model:
  vocab_size: 3593
  d_model: 512
  num_heads: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  dim_feedforward: 2048
  dropout: 0.1
  max_seq_length: 50
  embedding_dim: 512

# Image Processing
image:
  img_size: 224
  patch_size: 16
  num_channels: 3

# Training
training:
  batch_size: 8
  num_epochs: 30
  learning_rate: 0.0001
  num_workers: 4
  device: 'cuda'
  max_length: 50
  beam_size: 5
  gradient_clip_val: 1.0
  warmup_steps: 4000

# Logging
logging:
  project_name: "image-captioning-transformer"
  log_dir: "logs"
  save_dir: "checkpoints"
  log_every_n_steps: 100

# Data
data:
  dataset_name: "nlphuji/flickr30k"
  train_split: "test[:80%]"     # Use first 80% of test set for training
  val_split: "test[80%:90%]"    # Use next 10% for validation
  test_split: "test[90%:]"      # Use last 10% for testing 